import gym
import pandas as pd
import torch
from gym import spaces
import numpy as np
from stable_baselines3.common.vec_env import DummyVecEnv

class StockPortfolioEnv(gym.Env):
    def __init__(self, args, corr=None, ts_features=None, features=None,
                 ind=None, pos=None, neg=None, returns=None, pyg_data=None,
                 benchmark_return=None, mode="train", reward_net=None, device='cuda:0',
                 ind_yn=False, pos_yn=False, neg_yn=False):
        super(StockPortfolioEnv, self).__init__()
        self.current_step = 0
        self.max_step = returns.shape[0] - 1
        self.done = False
        self.reward = 0.0
        self.net_value = 1.0
        self.peak_value = 1.0  # Track peak wealth for drawdown calculation
        self.net_value_s = [1.0]
        self.daily_return_s = [0.0]
        self.num_stocks = returns.shape[-1]
        self.benchmark_return = benchmark_return

        self.corr_tensor = corr
        self.ts_features_tensor = ts_features
        self.features_tensor = features
        self.ind_tensor = ind
        self.pos_tensor = pos
        self.neg_tensor = neg
        self.pyg_data_batch = pyg_data
        self.ror_batch = returns
        self.ind_yn = ind_yn
        self.pos_yn = pos_yn
        self.neg_yn = neg_yn

        # # 动作空间：连续值，范围 [0, 1]
        # # 含义：股票 score
        # self.action_space = spaces.Box(low=0,
        #                                high=1,
        #                                shape=(self.num_stocks,),
        #                                dtype=np.float32)

        # 允许选择固定数量的股票（如 10%）
        self.top_k = max(1, int(0.1 * self.num_stocks))  # 每次选择的股票数
        # 动作空间：离散，表示选择的股票索引
        self.action_space = spaces.Box(low=0.0,
                               high=1.0,
                               shape=(self.num_stocks,),
                               dtype=np.float32)

        # 部分可观测
        # 观测空间：股票特征及各个关系图
        # HGAT expects flattened input: [ind_matrix, pos_matrix, neg_matrix, features]
        obs_len = 0
        if self.ind_yn:
            obs_len += self.num_stocks * self.num_stocks  # Flattened industry matrix
        else:
            obs_len += self.num_stocks * self.num_stocks  # Zeros placeholder
        if self.pos_yn:
            obs_len += self.num_stocks * self.num_stocks  # Flattened momentum matrix
        else:
            obs_len += self.num_stocks * self.num_stocks  # Zeros placeholder
        if self.neg_yn:
            obs_len += self.num_stocks * self.num_stocks  # Flattened reversal matrix
        else:
            obs_len += self.num_stocks * self.num_stocks  # Zeros placeholder
        obs_len += self.num_stocks * args.input_dim  # Flattened features
        
        self.observation_space = spaces.Box(low=-np.inf,
                                            high=np.inf,
                                            shape=(obs_len,),  # 1D flattened observation
                                            dtype=np.float32)
        self.mode = mode
        self.reward_net = reward_net  # 注入IRL奖励网络
        self.device = device

    def load_observation(self, ts_yn=False, ind_yn=False, pos_yn=False, neg_yn=False):
        # Stable-Baselines3 的 DummyVecEnv 需要将环境的观测值 (obs) 存储为 NumPy 数组
        if torch.isnan(self.features_tensor).any():
            print("nan！！！")
        features = self.features_tensor[self.current_step].cpu().numpy()  # [num_stocks, 6]
        corr_matrix = self.corr_tensor[self.current_step].cpu().numpy()
        ind_matrix = self.ind_tensor[self.current_step].cpu().numpy()  # [num_stocks, num_stocks]
        pos_matrix = self.pos_tensor[self.current_step].cpu().numpy()  # [num_stocks, num_stocks]
        neg_matrix = self.neg_tensor[self.current_step].cpu().numpy()  # [num_stocks, num_stocks]
        
        # HGAT expects: [ind_matrix, pos_matrix, neg_matrix, features] all flattened and concatenated
        # Reshape matrices to [num_stocks, num_stocks] and features to [num_stocks, 6]
        # Then flatten in the correct order for HGAT
        obs_parts = []
        if ind_yn:
            obs_parts.append(ind_matrix.flatten())  # [num_stocks * num_stocks]
        else:
            obs_parts.append(np.zeros(self.num_stocks * self.num_stocks))
            
        if pos_yn:
            obs_parts.append(pos_matrix.flatten())  # [num_stocks * num_stocks]
        else:
            obs_parts.append(np.zeros(self.num_stocks * self.num_stocks))
            
        if neg_yn:
            obs_parts.append(neg_matrix.flatten())  # [num_stocks * num_stocks]
        else:
            obs_parts.append(np.zeros(self.num_stocks * self.num_stocks))
        
        obs_parts.append(features.flatten())  # [num_stocks * 6]
        
        # Concatenate all parts into single vector
        obs = np.concatenate(obs_parts)  # Total: 3*num_stocks^2 + num_stocks*6
        
        self.observation = obs
        self.ror = self.ror_batch[self.current_step].cpu()


    def reset(self):
        self.current_step = 0
        self.done = False
        self.reward = 0.0
        self.net_value = 1.0
        self.peak_value = 1.0  # Reset peak value
        self.net_value_s = [1.0]
        self.daily_return_s = [0.0]
        self.load_observation(ind_yn=self.ind_yn, pos_yn=self.pos_yn, neg_yn=self.neg_yn)
        return self.observation

    def seed(self, seed):
        return np.random.seed(seed)

    def step(self, actions):
        self.done = self.current_step == self.max_step
        if self.done:
            if self.mode == "test":
                print("=================================")
                print(f"net_values:{self.net_value_s}")
                arr, avol, sharpe, mdd, cr, ir = self.evaluate()

                print("ARR: ", arr)
                print("AVOL: ", avol)
                print("Sharpe: ", sharpe)
                print("MDD: ", mdd)
                print("CR: ", cr)
                print("IR: ", ir)
                print("=================================")
        else:
            # load s'
            self.current_step += 1
            self.load_observation(ind_yn=self.ind_yn, pos_yn=self.pos_yn, neg_yn=self.neg_yn)

            # ---- NEW: continuous actions normalized to sum to 1 ----
            # actions may be a numpy array, list, or tensor. Ensure numpy array.
            if isinstance(actions, np.ndarray):
                a = actions.astype(np.float32)
            else:
                a = np.array(actions, dtype=np.float32)

            # clip to [0,1] to be robust
            a = np.clip(a, 0.0, 1.0)

            s = a.sum()
            if s <= 0:
                # if all zeros, fallback to uniform allocation
                weights = np.ones(self.num_stocks, dtype=np.float32) / float(self.num_stocks)
            else:
                weights = a / s  # normalized allocation vector summing to 1

            # Use IRL reward if available, else dot(weights, returns)
            if self.reward_net is not None:
                state_tensor = torch.FloatTensor(self.observation).to(self.device)
                action_tensor = torch.FloatTensor(weights).to(self.device)  # now a continuous weight vector
                wealth_info = torch.FloatTensor([self.net_value, self.peak_value]).to(self.device)
                with torch.no_grad():
                    self.reward = self.reward_net(state_tensor, action_tensor, wealth_info).mean().cpu().item()
            else:
                self.reward = float(np.dot(weights, np.array(self.ror)))
            
            self.net_value *= (1 + self.reward)
            self.peak_value = max(self.peak_value, self.net_value)
            self.daily_return_s.append(self.reward)
            self.net_value_s.append(self.net_value)

        return self.observation, self.reward, self.done, {}

    def get_sb_env(self):
        e = DummyVecEnv([lambda: self])
        obs = e.reset()
        return e, obs

    def get_df_net_value(self):
        df_net_value = pd.DataFrame(self.net_value_s)
        df_net_value.columns = ["net_value"]
        return df_net_value

    def get_df_daily_return(self):
        df_daily_return = pd.DataFrame(self.daily_return_s)
        df_daily_return.columns = ["daily_return"]
        return df_daily_return

    def evaluate(self):
        arr, avol, sp, mdd, cr, ir = (0, 0, 0, 0, 0, 0)
        df_daily_return = self.get_df_daily_return()
        if df_daily_return["daily_return"].std() != 0:
            # 年化收益 arr
            # 假设一年 252 个交易日
            arr = (1 + df_daily_return['daily_return'].mean()) ** 252 - 1
            # 年化波动率 AVOL
            avol = df_daily_return["daily_return"].std() * (252 ** 0.5)
            sp = (
                    (252 ** 0.5)
                    * df_daily_return["daily_return"].mean()
                    / df_daily_return["daily_return"].std()
            )
            # cumulative return
            df_daily_return['cumulative_return'] = (1 + df_daily_return['daily_return']).cumprod()
            # the running maximum
            running_max = df_daily_return['cumulative_return'].cummax()
            # drawdown
            drawdown = df_daily_return['cumulative_return'] / running_max - 1
            # Maximum Drawdown (MDD)
            mdd = drawdown.min()
            # Calmar Ratio (CR)
            if mdd != 0:
                cr = arr / abs(mdd)
            # 信息比率 IR（需要基准收益序列）
            if self.benchmark_return is not None:
                if len(self.benchmark_return) == len(df_daily_return):
                    ex_return = df_daily_return["daily_return"] -\
                                self.benchmark_return.reset_index(drop=True)
                    if ex_return.std() != 0:
                        ir = ex_return.mean() / ex_return.std() * (252 ** 0.5)
        return arr, avol, sp, mdd, cr, ir
